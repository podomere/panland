---
author: Donal
published: true
title: Why CVs and Résumés are broken
subtitle: And how simulations solve for Proof of Experience
tags:
  - cv
  - resume
  - job search
  - cover letter
  - time-to-hire
  - simulation based screening
  - scientific hiring
  - screening tips and tricks
  - sourcing tips and tricks
  - first principles
  - screening as a service
  - sourcing as a service
image: /images/blog/cv_broken.jpg
---
This may be a little difficult to swallow but CVs and resumes are fundamentally broken. Apart from the fact that it's difficult for someone to describe their own capabilities, it's even harder to do so **objectively**. During a job search, a candidate knows they're in a competitive environment so there's always pressure to inflate one's expertise a little to get noticed. Here's where [GIGO](https://en.wikipedia.org/wiki/Garbage_in,_garbage_out) kicks in yet few are willing to acknowledge its existence. Let me explain...

With the written word it's not difficult for _many_ to project themselves as an enterprising and dynamic achiever ( [Dunning–Kruger](https://en.wikipedia.org/wiki/Dunning%E2%80%93Kruger_effect) ), whilst some undersell themselves ( [The Confidence Gap](https://www.theatlantic.com/magazine/archive/2014/05/the-confidence-gap/359815/) ). Independent of resume format, with a little marketing spin and some flourishes here and there (and maybe some unethical [keyword stuffing](https://blog.pansift.com/2017-12-12-how-to-seo-hack-your-cv/) ) there's suddenly a problem of **validity** when sourcing or screening candidates. But who would do such a thing? Surely candidates are not all biased and only list current skills?

## Who does what?

So, apart from resume templates and a cover letter, CVs and profiles are, erm... **self-written** with a specific goal in mind! When a candidate embellishes or oversells their skills and experience, hiring teams get a percentage of non-trustworthy information. This misinformation influences who to engage with further during sourcing and screening. In computer parlance this defective input leads to what's called [GIGO](https://en.wikipedia.org/wiki/Garbage_in,_garbage_out) [(Garbage In, Garbage Out)](https://en.wikipedia.org/wiki/Garbage_in,_garbage_out). Albeit most people are trustworthy, candidates are still biased towards themselves. But is there any fault in _optimising_ a piece of _marketing literature_ for a specific goal? Where are the false advertising police I hear you cry and how much human time is spent checking the claims made?

## Curriculum Vitae, Résumé, or LinkedIn?

Unfortunately each method of encapsulating information is biased but still the de facto currency for initial decision making. Sometimes it's better to think of these artifacts and mediums as purely personal advertisements or **marketing flyers**. If they contain too much information a candidate risks losing the focus and attention of a human reader, too little, and not enough _surface_ or _context_ is exposed to be [found](https://blog.pansift.com/2017-12-12-how-to-seo-hack-your-cv/). Interestingly, job advertisements and position descriptions suffer similar issues with their phrasing and keywords which has lead to crowd sourced reviewing sites for companies. Either way, any keywords or claims should be _validatable_ and _verifiable_.

## Back Scratching for Fun and Profit

Asking colleagues or previous managers for references is also flawed and fraught with a societal weight for them to be overtly _positive_ (though in some jurisdictions managers are legally required to be wholly neutral). Candidates also tend to only nominate those whom they've had productive or good working relationships with. **Endorsements** on platforms like Linkedin create reciprocal pressure to sycophantically stroke the other persons ego... more [GIGO](https://en.wikipedia.org/wiki/Garbage_in,_garbage_out) alarms! So, must we revalidate every aspect of a candidate from scratch?

## Human or Machine Readable?

Currently it seems we're in an environment where candidates need to optimise CVs and profiles for both **human and machine** readability by: 
* telling a human story about the impact they've had in previous roles
* describing their capabilities and listing their expertise (skills)
* ensuring that any data mining, discovery, or re-discovery by [ATS / machine agents](https://blog.pansift.com/2017-12-12-how-to-seo-hack-your-cv/) is catered for ( e.g. [How to SEO hack your CV](https://blog.pansift.com/2017-12-12-how-to-seo-hack-your-cv/) )

## Proof of Work or Proof of Experience?

Services are available that can verify aspects of work history but few can validate actual experience or verify current expertise. If only there was a trusted blockchain or distributed ledger to prove global or local experience :) Personal tax numbers could potentially be used to validate work history but not expertise itself.

Being able to present artifacts of previous work (such as an artist's portfolio or showreel) goes a long way, but is not possible for everyone. For many, there are confidentiality clauses, sensitive client relationships, and opacity on projects which prevent demonstrating or showing previous work. In software development there's an ongoing debate about offering up repositories of public projects or records of contribution - however this suffers from the issues previously mentioned (amongst other flaws argued about at [length](https://blog.jcoglan.com/2013/11/15/why-github-is-not-your-cv/)). 

Certifications and qualifications are one form of communication compression which try to 'prove' expertise yet they don't guarantee skills are fresh. For an employee to hit the ground running it's imperative to differentiate between **theory and practice**. So how does a hiring team get past dubious documents and uncover evidence based data about a candidate's expertise?

## Test Driven Hiring and Structured Hiring

One increasingly popular option for hiring teams is to give the candidate tasks that simulate a real world scenario. This allows for them to be independently evaluated. Some organisations set take home projects but make unreasonable requests on a candidate’s time e.g. `4`-`20` hours or more. Many of these projects or tasks still require expert **human time** to grade them which doesn't scale and is costly.

<div class="card ">
  <h3 class="card-header"><b>PS</b></h3>
  <div class="card-body">At <a href="https://pansift.com/?utm_source=psblog&utm_medium=hyperlink&utm_campaign=launch&utm_content=sbs">PanSift</a> we recommend that organisations request no more that <code>40</code> minutes to <code>2</code> hours for an automated initial technical screen. By using <a href="https://en.wikipedia.org/wiki/Machine_learning" target="_blank"><b>ML </b>(Machine Learning)</a> and <a href="https://en.wikipedia.org/wiki/Natural_language_processing" target="_blank"><b>NLP </b>(Natural Language Processing)</a> we extract <b>testable skills</b> and then build <b>custom  simulations</b> to test claimed skills. You can also use predefined simulations or even drag and drop skills to build your own. This method is called <a href="https://pansift.com/?utm_source=psblog&utm_medium=hyperlink&utm_campaign=launch&utm_content=sbs">Simulation Based Screening</a> and it allows for wider funnels and less bias whilst saving costs and reducing <b>time to hire</b>.</div></div> 

Human time is expensive and a _resource_ best spent on evaluating a candidate's soft skills, collaboration, creativity, and attitude. Further depth of expertise can be checked by human experts once the candidate has proven they are in possession of the basic fundamental and desirable skills. Be it someone in talent acquisition, recruiting, management, or an internal domain expert, **time should not be wasted** administering and re-administering the same _hard skills_ test over and over again. Automation can be leveraged to (remotely or locally) separate the _wheat from the chaff_ and help identify those who are serious about committing to a role rather than those just playing the law of averages. 

<img src="/images/blog/time-to-hire-image-v7.png" class="w-100 mb-3">

If you don't have enough objective evidence to back up your decisions then it's highly likely **unconscious bias** will lead to expensive or bad hires. With the goals of reduced costs and faster _time to hire_, everyone's looking for non-zero sum games. As we're increasingly able to simulate different environments (and in the future via augmented reality and virtual reality) a range of different types of [Simulation Based Screening](https://pansift.com/?utm_source=psblog&utm_medium=hyperlink&utm_campaign=launch&utm_content=sbs) present themselves.
